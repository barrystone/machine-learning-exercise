{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "insurance-predict",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "J89Uq_xd7G6y"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# == Importing the dataset ==\n",
        "dataset = pd.read_csv('insurance.csv')\n",
        "x = dataset.iloc[:, :-1].values\n",
        "y = dataset.iloc[:, -1].values"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# == Taking care of missing data ==\n",
        "from sklearn.impute import SimpleImputer\n",
        "imputer = SimpleImputer(missing_values = np.nan, strategy = 'mean')\n",
        "imputer.fit(x[:,0:1])\n",
        "x[:,0:1] = imputer.transform(x[:,0:1])\n",
        "imputer.fit(x[:,2:4])\n",
        "x[:,2:4] = imputer.transform(x[:,2:4])"
      ],
      "metadata": {
        "id": "KqNAdok7wGBd"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# == Encoding categorical data ==\n",
        "## Encoding categorical data\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ct = ColumnTransformer(transformers = [('encoder',OneHotEncoder(),[1,4,5])],remainder = 'passthrough')\n",
        "x = np.array(ct.fit_transform(x))\n",
        "## Encoding the Dependent Variable\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)"
      ],
      "metadata": {
        "id": "z6bZCPd0wK6e"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# == Splitting the dataset into the Training set and Test set ==\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size =0.2, random_state =1)"
      ],
      "metadata": {
        "id": "8CaD3dR6wPxK"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# == Feature Scaling (Standardisation method) ==\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "x_train[:,8:] = sc.fit_transform(x_train[:,8:])\n",
        "x_test[:,8:] = sc.transform(x_test[:,8:])"
      ],
      "metadata": {
        "id": "pRvRyAzLwTMU"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Showing results\n",
        "print(\"\\n == x ==\")\n",
        "print(x)\n",
        "print(\"\\n == y ==\")\n",
        "print(y)\n",
        "print(\"\\n==============\")\n",
        "\n",
        "print(\"\\n == x_train ==\")\n",
        "print(x_train)\n",
        "print(\"\\n == x_test ==\")\n",
        "print(x_test)\n",
        "print(\"\\n == y_train ==\")\n",
        "print(y_train)\n",
        "print(\"\\n == y_test ==\")\n",
        "print(y_test)\n",
        "print(\"\\n\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lNQumS2wW3H",
        "outputId": "665ea449-2a09-4f0f-9b2c-f2422a8586b3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " == x ==\n",
            "[[1.0 0.0 0.0 ... 19.0 27.9 0.0]\n",
            " [0.0 1.0 1.0 ... 18.0 33.77 1.0]\n",
            " [0.0 1.0 1.0 ... 28.0 33.0 3.0]\n",
            " ...\n",
            " [1.0 0.0 1.0 ... 18.0 36.85 0.0]\n",
            " [1.0 0.0 1.0 ... 21.0 25.8 0.0]\n",
            " [1.0 0.0 0.0 ... 61.0 29.07 0.0]]\n",
            "\n",
            " == y ==\n",
            "[1005   57  306 ...   32   91 1171]\n",
            "\n",
            "==============\n",
            "\n",
            " == x_train ==\n",
            "[[1.0 0.0 1.0 ... 1.0022862943641633 -0.6647447195470174\n",
            "  -0.9070577122378711]\n",
            " [0.0 1.0 1.0 ... 1.0022862943641633 -1.51402368505697\n",
            "  -0.07894188280568505]\n",
            " [0.0 1.0 1.0 ... -1.5042660745131606 1.0811768460878646\n",
            "  -0.9070577122378711]\n",
            " ...\n",
            " [1.0 0.0 0.0 ... 0.8590547304283163 0.7006345403882132 0.749173946626501]\n",
            " [1.0 0.0 0.0 ... 0.0712811287811573 -1.3800989251111697\n",
            "  0.749173946626501]\n",
            " [0.0 1.0 1.0 ... 1.2887494222358575 -0.44589206305022205\n",
            "  -0.07894188280568505]]\n",
            "\n",
            " == x_test ==\n",
            "[[0.0 1.0 1.0 ... -1.4326502925452371 0.7937285808383426\n",
            "  -0.9070577122378711]\n",
            " [0.0 1.0 1.0 ... 1.2887494222358575 0.14207029768743673\n",
            "  -0.9070577122378711]\n",
            " [0.0 1.0 1.0 ... 0.8590547304283163 1.0338132114728866\n",
            "  -0.9070577122378711]\n",
            " ...\n",
            " [0.0 1.0 0.0 ... 0.5725916025566221 1.3506595947592914 0.749173946626501]\n",
            " [1.0 0.0 1.0 ... -1.4326502925452371 0.9644009883302467\n",
            "  -0.9070577122378711]\n",
            " [1.0 0.0 1.0 ... -0.28679778105846043 -0.7423230865887921\n",
            "  -0.9070577122378711]]\n",
            "\n",
            " == y_train ==\n",
            "[ 730  712    6 ... 1298 1052  813]\n",
            "\n",
            " == y_test ==\n",
            "[  42  794  631  732   98 1242  665  817  195 1056  881  811  451  504\n",
            "    5  644 1097  460 1164  926  691 1265  571  602  116  479  622  591\n",
            "  386  241  819  822 1133 1190 1122  700 1220 1023  834 1252  293  825\n",
            " 1060  866  354 1178 1160 1199  688  963  875  836  133  650 1010  267\n",
            " 1266  884 1102    8  218  910 1031  162  888  629  726 1099  165  973\n",
            " 1334 1333   63  871  917 1268  175  182  774  739  198  863  764   86\n",
            " 1246 1276  501 1306  731  562 1068 1121  943  637   31  675  699  861\n",
            "  859  458  795  988 1029 1200 1153 1024   62  538  123  788  299  264\n",
            "   35  986  878   14  480  955 1053  128  640  753  425  508 1288  680\n",
            "  905 1050 1289  560 1217   71  507 1236 1129   61   36   34  710  565\n",
            "  950  420 1042  958  930  745   55  566   58  481  511  256 1187  835\n",
            "  564  422  709  708  674   70  244 1329  843  186  436   23 1240  736\n",
            "  775  397  369  233 1103 1142  217  469  138  974  245  415  887  931\n",
            "  646  553  239 1028  109  615  545  656  951 1313  210  164  496  659\n",
            "  522  103  809  585  447  534  848 1115  463   25  473  502   89  805\n",
            "  277 1111 1009  265  326 1314  756 1209    3 1244  142 1082  862  342\n",
            "   40   84  295  755 1007  942  237  948 1317  485  849  723 1013   41\n",
            "  596  273  576   94 1181   88 1077 1132 1037  613 1026  953  766  305\n",
            "  853  740  183  173 1198 1101   29 1322  583  497  586 1259 1284 1292\n",
            "  104  371]\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "regressor = LinearRegression()\n",
        "regressor.fit(x_train, y_train)\n",
        "\n",
        "y_pred = regressor.predict(x_test)\n",
        "print(\"== Predicting the Test set results (Multiple Linear Regression) ==\")\n",
        "print(y_pred)\n",
        "\n",
        "print(\"\\n == Predicting single result (row-50) ==\")\n",
        "print(regressor.predict([[0.0,1.0,1.0,0.0,0.0,0.0,1.0,0.0,1.5752125501075516,0.1469699840269174,-0.9070577122378711\n",
        "]]))\n",
        "print(\"row-50: \", y_pred[50])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6BvDMu2wc-l",
        "outputId": "0f564002-8bb1-44a4-f6c5-d7aa7a61a9b6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Predicting the Test set results (Multiple Linear Regression) ==\n",
            "[ 217.375  758.25   669.375  760.375  192.625 1118.25   701.25   797.375\n",
            "  325.875 1089.25   778.625  849.5    531.125  564.25   172.     654.625\n",
            "  366.     515.25   847.25   847.25   725.625 1132.375  612.625  608.25\n",
            "  245.5    538.875  656.625  641.375  479.125  367.375  800.375  434.5\n",
            " 1456.125  841.25  1338.125  667.25   992.875  937.     814.    1280.\n",
            "  405.625  785.75   735.875  817.375  408.25   822.5    235.125  946.5\n",
            "  642.875  932.375  791.5    788.375  237.875  653.375  869.     454.75\n",
            " 1294.5    826.25   352.375  210.25   371.875  859.25   922.625  276.125\n",
            "  859.75   659.125  717.5    761.875  231.5    930.875 1427.5   1142.125\n",
            "  195.75   805.75   825.    1270.5    269.625  304.75   723.75   724.375\n",
            "  260.125  830.5    732.25   238.125 1216.625 1024.     547.75  1330.\n",
            "  775.375  622.5   1092.125 1402.875  873.125  666.375  159.75   664.5\n",
            "  682.25   837.375  828.     525.5    769.25   894.75  1033.75   828.875\n",
            " 1471.     917.     177.     580.75   247.875  788.25   410.5    362.5\n",
            "  171.125  979.75   281.75   161.875  578.125  850.625  623.875  249.\n",
            "  636.875  796.875  512.5    530.25  1418.375  702.75   857.875 1106.625\n",
            " 1284.875  626.625  828.375  156.875  589.125 1068.     554.     158.75\n",
            "  172.875  222.375  658.875  678.875  899.625  511.    1066.     888.5\n",
            "  901.     711.5    179.25   625.25   205.25   520.5    600.375  359.25\n",
            "  804.125  829.5    638.625  492.     736.5    716.25   704.125  246.125\n",
            "  373.875 1559.125  779.125  300.5    520.5    226.875 1109.75   708.625\n",
            "  732.25   499.5    450.625  379.25  1364.875 1425.5    305.25   556.75\n",
            "  279.5    948.     335.25   554.625  827.125  841.75   666.5    678.25\n",
            "  310.375  920.5    235.625  710.125  544.375  697.     880.125 1404.25\n",
            "  301.25   231.     517.75   629.25   565.25   248.625  757.625  618.375\n",
            "  539.     615.5    773.625  539.     528.5    170.875  582.875  551.125\n",
            "  287.375  753.625  412.125 1338.625  435.     382.     441.75  1567.875\n",
            "  750.625  978.875  168.5   1235.625  277.    1266.     827.125  383.625\n",
            "  183.     211.75   415.625  274.625  833.125  877.625  331.     868.125\n",
            " 1394.5    520.75   829.     696.5   1022.875  195.375  694.875  388.\n",
            "  686.625  271.875  952.375  249.375  709.625 1415.125  603.25   651.125\n",
            "  328.25   889.625  788.625  418.375  750.75   741.875  326.375  347.5\n",
            "  866.75  1229.875  150.    1575.5    626.625  544.25   642.375 1184.875\n",
            " 1273.25  1318.     255.     477.625]\n",
            "\n",
            " == Predicting single result (row-50) ==\n",
            "[791.125]\n",
            "row-50:  791.5\n"
          ]
        }
      ]
    }
  ]
}